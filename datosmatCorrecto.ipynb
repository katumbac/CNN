{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var\n",
    "\n",
    "#input_shape=(longitud_temporal, canales)\n",
    "fs = 256\n",
    "longitud_temporal= int(1.50 * fs)\n",
    "canales=16\n",
    "\n",
    "time_length=int(1.50 * fs)\n",
    "channels=16\n",
    "\n",
    "#red neuronal - compitlacion del model cnn 1D\n",
    "optimizer='adam'\n",
    "loss='mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"datos mat\\Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RED NEURONAL CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_shape=(385,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear modelo de red neuronal con Conv1D\n",
    "model = models.Sequential([\n",
    "    layers.Conv1D(64, 3, activation='relu', input_shape=input_shape), #capa de entrada, en esta capa se establece formato de entrada\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='softmax')  # Capa de salida con una neurona para clasificación binaria\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Usar categorical_crossentropy para clasificación multiclase\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">383</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3008</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">192,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m383\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m3,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m189\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3008\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m192,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,953</span> (788.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,953\u001b[0m (788.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,953</span> (788.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,953\u001b[0m (788.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRUEBA RED NEURONAL CNN CONV1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  tensor([[[1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.]]])\n",
      "net =  Conv1d(16, 16, kernel_size=(3,), stride=(1,))\n",
      "Parameters =  [Parameter containing:\n",
      "tensor([[[ 0.0828, -0.0588,  0.0344],\n",
      "         [ 0.0405, -0.0625, -0.1097],\n",
      "         [-0.0308,  0.1257,  0.1027],\n",
      "         [-0.1277,  0.0406, -0.0532],\n",
      "         [ 0.0992,  0.1398, -0.0227],\n",
      "         [-0.0310, -0.0338,  0.1415],\n",
      "         [ 0.1427,  0.0627,  0.0201],\n",
      "         [ 0.0754,  0.0577, -0.1096],\n",
      "         [-0.0105,  0.1355, -0.1326],\n",
      "         [-0.1130, -0.1034, -0.0625],\n",
      "         [-0.0933, -0.1116, -0.1111],\n",
      "         [ 0.0393, -0.0137,  0.0997],\n",
      "         [-0.1191,  0.0995,  0.0402],\n",
      "         [-0.0515, -0.1379,  0.0198],\n",
      "         [ 0.1227,  0.1392,  0.0523],\n",
      "         [ 0.0051, -0.0712, -0.0413]],\n",
      "\n",
      "        [[-0.1383,  0.0356,  0.0485],\n",
      "         [-0.0987,  0.0685, -0.1191],\n",
      "         [-0.0605, -0.0198,  0.0653],\n",
      "         [ 0.0590, -0.0110,  0.0724],\n",
      "         [ 0.1138,  0.0965, -0.0029],\n",
      "         [-0.0226, -0.0896,  0.0813],\n",
      "         [-0.0540,  0.0003,  0.0476],\n",
      "         [ 0.0885,  0.1433, -0.0619],\n",
      "         [ 0.0685,  0.0588, -0.0641],\n",
      "         [ 0.0873, -0.1036,  0.0227],\n",
      "         [ 0.1401,  0.0639,  0.0969],\n",
      "         [ 0.0266,  0.1305, -0.1300],\n",
      "         [-0.1203, -0.0740, -0.0259],\n",
      "         [-0.0423, -0.0972, -0.1339],\n",
      "         [ 0.0046,  0.0936, -0.0142],\n",
      "         [ 0.0541,  0.1171,  0.1385]],\n",
      "\n",
      "        [[ 0.0227,  0.0988, -0.0841],\n",
      "         [ 0.0588, -0.0509, -0.1009],\n",
      "         [ 0.0460,  0.0514,  0.0833],\n",
      "         [ 0.1088, -0.0417, -0.1038],\n",
      "         [ 0.1064, -0.1032, -0.0960],\n",
      "         [-0.0944,  0.1403,  0.0233],\n",
      "         [ 0.0620, -0.1120, -0.0183],\n",
      "         [ 0.0432, -0.0882, -0.1309],\n",
      "         [ 0.0936,  0.0839, -0.0932],\n",
      "         [-0.1235,  0.0918, -0.0142],\n",
      "         [-0.1231, -0.0385,  0.1402],\n",
      "         [ 0.0030, -0.0198, -0.0060],\n",
      "         [-0.1349, -0.0683,  0.0302],\n",
      "         [-0.1089,  0.0301,  0.0907],\n",
      "         [ 0.1378, -0.0973, -0.0984],\n",
      "         [ 0.0831, -0.0877,  0.1109]],\n",
      "\n",
      "        [[ 0.0989, -0.1030,  0.0812],\n",
      "         [-0.0760, -0.1350,  0.0832],\n",
      "         [ 0.0561,  0.0673,  0.0481],\n",
      "         [-0.1344, -0.0685,  0.0317],\n",
      "         [-0.0291, -0.1221, -0.1104],\n",
      "         [ 0.0650, -0.1152, -0.0491],\n",
      "         [ 0.1109,  0.0853,  0.0729],\n",
      "         [-0.1163, -0.0788,  0.0777],\n",
      "         [ 0.1282,  0.1183,  0.1338],\n",
      "         [ 0.0563, -0.1162,  0.1274],\n",
      "         [-0.0964,  0.0488, -0.0823],\n",
      "         [ 0.0804, -0.1036,  0.0305],\n",
      "         [ 0.0708,  0.1301, -0.0893],\n",
      "         [-0.0335, -0.0819, -0.0129],\n",
      "         [ 0.0195, -0.1192,  0.0894],\n",
      "         [ 0.0902, -0.0862, -0.1227]],\n",
      "\n",
      "        [[ 0.1311,  0.0647,  0.1013],\n",
      "         [-0.0737,  0.0618, -0.0798],\n",
      "         [-0.1244, -0.0099,  0.0206],\n",
      "         [ 0.1034, -0.0621,  0.0185],\n",
      "         [ 0.0638,  0.1000, -0.1370],\n",
      "         [-0.0890, -0.1309, -0.1164],\n",
      "         [ 0.0366, -0.0286,  0.1154],\n",
      "         [ 0.1083,  0.0566, -0.0027],\n",
      "         [-0.1107, -0.0684,  0.1422],\n",
      "         [ 0.1237, -0.1097, -0.1064],\n",
      "         [-0.0210, -0.0377, -0.0973],\n",
      "         [ 0.0069, -0.0042, -0.0484],\n",
      "         [-0.0649, -0.0151,  0.0870],\n",
      "         [ 0.0739,  0.0604, -0.0204],\n",
      "         [-0.1175,  0.0735, -0.0937],\n",
      "         [ 0.0344, -0.0021,  0.0984]],\n",
      "\n",
      "        [[-0.0310,  0.0021,  0.1040],\n",
      "         [ 0.0324, -0.1428,  0.0600],\n",
      "         [-0.0553,  0.1197,  0.0169],\n",
      "         [ 0.1293, -0.0750,  0.0486],\n",
      "         [-0.0310,  0.0366, -0.0919],\n",
      "         [ 0.0746, -0.0584,  0.0074],\n",
      "         [ 0.1360, -0.0237,  0.0564],\n",
      "         [-0.1139, -0.1439, -0.0798],\n",
      "         [-0.1289,  0.0769,  0.0056],\n",
      "         [ 0.1037, -0.0654,  0.0460],\n",
      "         [ 0.0044, -0.1311,  0.1118],\n",
      "         [-0.0364,  0.1441,  0.0441],\n",
      "         [-0.1002,  0.0684, -0.1230],\n",
      "         [ 0.0249, -0.0487,  0.0371],\n",
      "         [ 0.0195, -0.0391,  0.0359],\n",
      "         [ 0.1027,  0.0531, -0.0629]],\n",
      "\n",
      "        [[-0.1056,  0.0390, -0.0647],\n",
      "         [ 0.0460, -0.0718,  0.0317],\n",
      "         [ 0.0661, -0.0992,  0.1317],\n",
      "         [ 0.0431,  0.0312, -0.1243],\n",
      "         [-0.0701, -0.0434, -0.0382],\n",
      "         [ 0.0635,  0.0364,  0.0610],\n",
      "         [-0.0635, -0.0511, -0.0521],\n",
      "         [-0.1398, -0.0990,  0.0952],\n",
      "         [-0.1299,  0.1053, -0.1000],\n",
      "         [-0.0418,  0.0581,  0.1225],\n",
      "         [-0.0289,  0.0279, -0.0220],\n",
      "         [-0.0364,  0.1111, -0.1398],\n",
      "         [-0.0175,  0.1378, -0.0632],\n",
      "         [ 0.1290, -0.1138, -0.0746],\n",
      "         [-0.0113, -0.1311,  0.1199],\n",
      "         [-0.1231,  0.0495,  0.0929]],\n",
      "\n",
      "        [[ 0.0054, -0.1117, -0.0497],\n",
      "         [ 0.0340, -0.1146,  0.0016],\n",
      "         [ 0.0018, -0.1057, -0.0946],\n",
      "         [ 0.0395,  0.0097,  0.1312],\n",
      "         [-0.0579, -0.0295,  0.0382],\n",
      "         [ 0.0407,  0.0099, -0.0433],\n",
      "         [ 0.1255,  0.0783, -0.1255],\n",
      "         [-0.1404, -0.0249, -0.1122],\n",
      "         [ 0.0913,  0.0534, -0.0072],\n",
      "         [ 0.0608, -0.0227, -0.0917],\n",
      "         [-0.0072,  0.0332, -0.0062],\n",
      "         [ 0.1341, -0.1433,  0.0629],\n",
      "         [-0.0047, -0.0053, -0.0434],\n",
      "         [-0.1175, -0.0128,  0.1113],\n",
      "         [-0.0616,  0.0234,  0.0337],\n",
      "         [ 0.0014, -0.1072, -0.1240]],\n",
      "\n",
      "        [[-0.0460, -0.0890,  0.0483],\n",
      "         [ 0.0421, -0.0867, -0.1257],\n",
      "         [ 0.0053,  0.1441,  0.0237],\n",
      "         [-0.0580,  0.1115,  0.0434],\n",
      "         [ 0.0608, -0.0830,  0.1036],\n",
      "         [ 0.0841, -0.0833, -0.1086],\n",
      "         [-0.1284, -0.0191,  0.0808],\n",
      "         [-0.0156, -0.0207, -0.0257],\n",
      "         [ 0.0294,  0.0906, -0.0216],\n",
      "         [-0.0782, -0.0501, -0.1135],\n",
      "         [-0.1305,  0.0988, -0.1410],\n",
      "         [-0.0032, -0.0138,  0.1342],\n",
      "         [-0.0483,  0.0552, -0.0743],\n",
      "         [ 0.0339,  0.0162, -0.1367],\n",
      "         [-0.1112,  0.0808, -0.0966],\n",
      "         [-0.1011, -0.0609,  0.0561]],\n",
      "\n",
      "        [[ 0.1385,  0.1217, -0.0197],\n",
      "         [-0.1433, -0.0258, -0.1181],\n",
      "         [ 0.0748,  0.0981, -0.0615],\n",
      "         [-0.0648, -0.0533,  0.0766],\n",
      "         [-0.0933, -0.0703, -0.0527],\n",
      "         [-0.0674, -0.0665, -0.1403],\n",
      "         [-0.0388,  0.0205,  0.1310],\n",
      "         [-0.1234, -0.0282, -0.0157],\n",
      "         [ 0.1089,  0.1058,  0.0908],\n",
      "         [-0.0165,  0.0602, -0.0992],\n",
      "         [-0.0588, -0.1234, -0.0583],\n",
      "         [ 0.0669,  0.0952,  0.0012],\n",
      "         [-0.0146,  0.0745,  0.0460],\n",
      "         [-0.1087,  0.0184,  0.0595],\n",
      "         [-0.1322, -0.1215, -0.0091],\n",
      "         [-0.0252, -0.0220, -0.1007]],\n",
      "\n",
      "        [[-0.0982,  0.1169,  0.0933],\n",
      "         [-0.0875,  0.0158,  0.0307],\n",
      "         [-0.0999, -0.0656, -0.1033],\n",
      "         [-0.0348, -0.0603, -0.1047],\n",
      "         [-0.0342,  0.0823,  0.1048],\n",
      "         [-0.0138, -0.0642, -0.0760],\n",
      "         [-0.1065, -0.0205, -0.0791],\n",
      "         [-0.0459,  0.1413, -0.0827],\n",
      "         [-0.0751, -0.0046,  0.0241],\n",
      "         [-0.1135,  0.1251,  0.0232],\n",
      "         [-0.0934, -0.0481, -0.1284],\n",
      "         [-0.0021, -0.0561,  0.0570],\n",
      "         [-0.1344,  0.0355, -0.0720],\n",
      "         [-0.0253,  0.0840,  0.0421],\n",
      "         [ 0.0068,  0.0308, -0.1347],\n",
      "         [ 0.0942,  0.0530,  0.0104]],\n",
      "\n",
      "        [[-0.1016,  0.0139, -0.0913],\n",
      "         [-0.1218, -0.0173,  0.1265],\n",
      "         [ 0.0883,  0.0660,  0.0298],\n",
      "         [ 0.0801,  0.1393, -0.0912],\n",
      "         [ 0.0842,  0.1401, -0.0228],\n",
      "         [-0.0995,  0.0290, -0.0444],\n",
      "         [-0.0559, -0.0646,  0.0880],\n",
      "         [-0.0396, -0.0736,  0.0428],\n",
      "         [-0.1345,  0.0059,  0.0634],\n",
      "         [ 0.1363,  0.0166, -0.0824],\n",
      "         [-0.0213,  0.0133,  0.0088],\n",
      "         [ 0.1148,  0.0164, -0.1272],\n",
      "         [ 0.0778,  0.1183,  0.0377],\n",
      "         [-0.0901, -0.0318,  0.0382],\n",
      "         [ 0.1104, -0.0122, -0.0199],\n",
      "         [-0.1406,  0.0632,  0.0385]],\n",
      "\n",
      "        [[ 0.0566, -0.0787,  0.0595],\n",
      "         [-0.0483,  0.0967,  0.0010],\n",
      "         [ 0.0647,  0.0945, -0.0372],\n",
      "         [-0.1210, -0.0171, -0.0669],\n",
      "         [ 0.0775,  0.0723, -0.1309],\n",
      "         [ 0.0136,  0.0707,  0.0157],\n",
      "         [-0.1405,  0.0355, -0.0359],\n",
      "         [ 0.1223, -0.1279,  0.1276],\n",
      "         [-0.0263, -0.0225,  0.0851],\n",
      "         [ 0.0032, -0.0126, -0.1087],\n",
      "         [ 0.0311,  0.0188, -0.0002],\n",
      "         [ 0.1290, -0.0708,  0.0835],\n",
      "         [ 0.0311, -0.1101, -0.0017],\n",
      "         [ 0.0616,  0.1287,  0.1094],\n",
      "         [ 0.0758, -0.0643,  0.0101],\n",
      "         [ 0.1156, -0.0116,  0.0083]],\n",
      "\n",
      "        [[ 0.1006,  0.0834, -0.0279],\n",
      "         [ 0.0318,  0.0448,  0.1004],\n",
      "         [-0.1047, -0.0681,  0.0713],\n",
      "         [-0.1306, -0.1153, -0.0660],\n",
      "         [ 0.1188,  0.1155, -0.0534],\n",
      "         [ 0.1082,  0.0012, -0.0734],\n",
      "         [-0.0430,  0.1280, -0.1281],\n",
      "         [ 0.0944, -0.0665,  0.0016],\n",
      "         [-0.1401, -0.0696, -0.1007],\n",
      "         [ 0.1378,  0.0356, -0.0791],\n",
      "         [-0.1103,  0.0251, -0.0560],\n",
      "         [-0.0075, -0.0728,  0.0344],\n",
      "         [-0.0458,  0.0755,  0.0479],\n",
      "         [ 0.1345, -0.1012, -0.0003],\n",
      "         [ 0.0062,  0.0851, -0.0463],\n",
      "         [-0.0793,  0.0977, -0.0365]],\n",
      "\n",
      "        [[-0.1205,  0.0428, -0.1134],\n",
      "         [-0.1078, -0.0502, -0.0744],\n",
      "         [-0.0865,  0.0175, -0.0431],\n",
      "         [ 0.0984, -0.0841,  0.1210],\n",
      "         [-0.1391, -0.1437, -0.1390],\n",
      "         [ 0.0326,  0.0117,  0.0349],\n",
      "         [ 0.1172,  0.1255,  0.1404],\n",
      "         [ 0.1428, -0.0460,  0.1318],\n",
      "         [-0.0541, -0.1197,  0.0863],\n",
      "         [ 0.0692,  0.0460,  0.0458],\n",
      "         [ 0.0366, -0.0335, -0.0999],\n",
      "         [-0.0299,  0.1094,  0.0592],\n",
      "         [ 0.0864,  0.0233,  0.0857],\n",
      "         [ 0.0280,  0.1164, -0.0875],\n",
      "         [-0.1378, -0.0554, -0.0470],\n",
      "         [-0.0826,  0.1186,  0.1380]],\n",
      "\n",
      "        [[-0.1413, -0.1263,  0.0489],\n",
      "         [ 0.0318, -0.0694,  0.1035],\n",
      "         [ 0.0378,  0.0427, -0.0405],\n",
      "         [ 0.0976,  0.1286,  0.0075],\n",
      "         [-0.0516,  0.0747,  0.0680],\n",
      "         [ 0.0392, -0.1286, -0.0826],\n",
      "         [ 0.0031,  0.0958, -0.0525],\n",
      "         [-0.0221, -0.1076, -0.0376],\n",
      "         [ 0.1085,  0.0723,  0.0612],\n",
      "         [ 0.0848, -0.0915,  0.0363],\n",
      "         [ 0.0826, -0.0306, -0.0666],\n",
      "         [ 0.0877, -0.0423,  0.0362],\n",
      "         [ 0.0849, -0.1150,  0.0797],\n",
      "         [-0.1022,  0.0371, -0.1098],\n",
      "         [-0.1373,  0.0563,  0.0055],\n",
      "         [ 0.1382,  0.0364, -0.0091]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0642,  0.1266,  0.0826,  0.0117,  0.0079,  0.0220,  0.1417, -0.1398,\n",
      "        -0.0682,  0.0890, -0.0073,  0.0135, -0.0624, -0.1037,  0.0366,  0.1433],\n",
      "       requires_grad=True)]\n",
      "Weight =  Parameter containing:\n",
      "tensor([[[ 0.0828, -0.0588,  0.0344],\n",
      "         [ 0.0405, -0.0625, -0.1097],\n",
      "         [-0.0308,  0.1257,  0.1027],\n",
      "         [-0.1277,  0.0406, -0.0532],\n",
      "         [ 0.0992,  0.1398, -0.0227],\n",
      "         [-0.0310, -0.0338,  0.1415],\n",
      "         [ 0.1427,  0.0627,  0.0201],\n",
      "         [ 0.0754,  0.0577, -0.1096],\n",
      "         [-0.0105,  0.1355, -0.1326],\n",
      "         [-0.1130, -0.1034, -0.0625],\n",
      "         [-0.0933, -0.1116, -0.1111],\n",
      "         [ 0.0393, -0.0137,  0.0997],\n",
      "         [-0.1191,  0.0995,  0.0402],\n",
      "         [-0.0515, -0.1379,  0.0198],\n",
      "         [ 0.1227,  0.1392,  0.0523],\n",
      "         [ 0.0051, -0.0712, -0.0413]],\n",
      "\n",
      "        [[-0.1383,  0.0356,  0.0485],\n",
      "         [-0.0987,  0.0685, -0.1191],\n",
      "         [-0.0605, -0.0198,  0.0653],\n",
      "         [ 0.0590, -0.0110,  0.0724],\n",
      "         [ 0.1138,  0.0965, -0.0029],\n",
      "         [-0.0226, -0.0896,  0.0813],\n",
      "         [-0.0540,  0.0003,  0.0476],\n",
      "         [ 0.0885,  0.1433, -0.0619],\n",
      "         [ 0.0685,  0.0588, -0.0641],\n",
      "         [ 0.0873, -0.1036,  0.0227],\n",
      "         [ 0.1401,  0.0639,  0.0969],\n",
      "         [ 0.0266,  0.1305, -0.1300],\n",
      "         [-0.1203, -0.0740, -0.0259],\n",
      "         [-0.0423, -0.0972, -0.1339],\n",
      "         [ 0.0046,  0.0936, -0.0142],\n",
      "         [ 0.0541,  0.1171,  0.1385]],\n",
      "\n",
      "        [[ 0.0227,  0.0988, -0.0841],\n",
      "         [ 0.0588, -0.0509, -0.1009],\n",
      "         [ 0.0460,  0.0514,  0.0833],\n",
      "         [ 0.1088, -0.0417, -0.1038],\n",
      "         [ 0.1064, -0.1032, -0.0960],\n",
      "         [-0.0944,  0.1403,  0.0233],\n",
      "         [ 0.0620, -0.1120, -0.0183],\n",
      "         [ 0.0432, -0.0882, -0.1309],\n",
      "         [ 0.0936,  0.0839, -0.0932],\n",
      "         [-0.1235,  0.0918, -0.0142],\n",
      "         [-0.1231, -0.0385,  0.1402],\n",
      "         [ 0.0030, -0.0198, -0.0060],\n",
      "         [-0.1349, -0.0683,  0.0302],\n",
      "         [-0.1089,  0.0301,  0.0907],\n",
      "         [ 0.1378, -0.0973, -0.0984],\n",
      "         [ 0.0831, -0.0877,  0.1109]],\n",
      "\n",
      "        [[ 0.0989, -0.1030,  0.0812],\n",
      "         [-0.0760, -0.1350,  0.0832],\n",
      "         [ 0.0561,  0.0673,  0.0481],\n",
      "         [-0.1344, -0.0685,  0.0317],\n",
      "         [-0.0291, -0.1221, -0.1104],\n",
      "         [ 0.0650, -0.1152, -0.0491],\n",
      "         [ 0.1109,  0.0853,  0.0729],\n",
      "         [-0.1163, -0.0788,  0.0777],\n",
      "         [ 0.1282,  0.1183,  0.1338],\n",
      "         [ 0.0563, -0.1162,  0.1274],\n",
      "         [-0.0964,  0.0488, -0.0823],\n",
      "         [ 0.0804, -0.1036,  0.0305],\n",
      "         [ 0.0708,  0.1301, -0.0893],\n",
      "         [-0.0335, -0.0819, -0.0129],\n",
      "         [ 0.0195, -0.1192,  0.0894],\n",
      "         [ 0.0902, -0.0862, -0.1227]],\n",
      "\n",
      "        [[ 0.1311,  0.0647,  0.1013],\n",
      "         [-0.0737,  0.0618, -0.0798],\n",
      "         [-0.1244, -0.0099,  0.0206],\n",
      "         [ 0.1034, -0.0621,  0.0185],\n",
      "         [ 0.0638,  0.1000, -0.1370],\n",
      "         [-0.0890, -0.1309, -0.1164],\n",
      "         [ 0.0366, -0.0286,  0.1154],\n",
      "         [ 0.1083,  0.0566, -0.0027],\n",
      "         [-0.1107, -0.0684,  0.1422],\n",
      "         [ 0.1237, -0.1097, -0.1064],\n",
      "         [-0.0210, -0.0377, -0.0973],\n",
      "         [ 0.0069, -0.0042, -0.0484],\n",
      "         [-0.0649, -0.0151,  0.0870],\n",
      "         [ 0.0739,  0.0604, -0.0204],\n",
      "         [-0.1175,  0.0735, -0.0937],\n",
      "         [ 0.0344, -0.0021,  0.0984]],\n",
      "\n",
      "        [[-0.0310,  0.0021,  0.1040],\n",
      "         [ 0.0324, -0.1428,  0.0600],\n",
      "         [-0.0553,  0.1197,  0.0169],\n",
      "         [ 0.1293, -0.0750,  0.0486],\n",
      "         [-0.0310,  0.0366, -0.0919],\n",
      "         [ 0.0746, -0.0584,  0.0074],\n",
      "         [ 0.1360, -0.0237,  0.0564],\n",
      "         [-0.1139, -0.1439, -0.0798],\n",
      "         [-0.1289,  0.0769,  0.0056],\n",
      "         [ 0.1037, -0.0654,  0.0460],\n",
      "         [ 0.0044, -0.1311,  0.1118],\n",
      "         [-0.0364,  0.1441,  0.0441],\n",
      "         [-0.1002,  0.0684, -0.1230],\n",
      "         [ 0.0249, -0.0487,  0.0371],\n",
      "         [ 0.0195, -0.0391,  0.0359],\n",
      "         [ 0.1027,  0.0531, -0.0629]],\n",
      "\n",
      "        [[-0.1056,  0.0390, -0.0647],\n",
      "         [ 0.0460, -0.0718,  0.0317],\n",
      "         [ 0.0661, -0.0992,  0.1317],\n",
      "         [ 0.0431,  0.0312, -0.1243],\n",
      "         [-0.0701, -0.0434, -0.0382],\n",
      "         [ 0.0635,  0.0364,  0.0610],\n",
      "         [-0.0635, -0.0511, -0.0521],\n",
      "         [-0.1398, -0.0990,  0.0952],\n",
      "         [-0.1299,  0.1053, -0.1000],\n",
      "         [-0.0418,  0.0581,  0.1225],\n",
      "         [-0.0289,  0.0279, -0.0220],\n",
      "         [-0.0364,  0.1111, -0.1398],\n",
      "         [-0.0175,  0.1378, -0.0632],\n",
      "         [ 0.1290, -0.1138, -0.0746],\n",
      "         [-0.0113, -0.1311,  0.1199],\n",
      "         [-0.1231,  0.0495,  0.0929]],\n",
      "\n",
      "        [[ 0.0054, -0.1117, -0.0497],\n",
      "         [ 0.0340, -0.1146,  0.0016],\n",
      "         [ 0.0018, -0.1057, -0.0946],\n",
      "         [ 0.0395,  0.0097,  0.1312],\n",
      "         [-0.0579, -0.0295,  0.0382],\n",
      "         [ 0.0407,  0.0099, -0.0433],\n",
      "         [ 0.1255,  0.0783, -0.1255],\n",
      "         [-0.1404, -0.0249, -0.1122],\n",
      "         [ 0.0913,  0.0534, -0.0072],\n",
      "         [ 0.0608, -0.0227, -0.0917],\n",
      "         [-0.0072,  0.0332, -0.0062],\n",
      "         [ 0.1341, -0.1433,  0.0629],\n",
      "         [-0.0047, -0.0053, -0.0434],\n",
      "         [-0.1175, -0.0128,  0.1113],\n",
      "         [-0.0616,  0.0234,  0.0337],\n",
      "         [ 0.0014, -0.1072, -0.1240]],\n",
      "\n",
      "        [[-0.0460, -0.0890,  0.0483],\n",
      "         [ 0.0421, -0.0867, -0.1257],\n",
      "         [ 0.0053,  0.1441,  0.0237],\n",
      "         [-0.0580,  0.1115,  0.0434],\n",
      "         [ 0.0608, -0.0830,  0.1036],\n",
      "         [ 0.0841, -0.0833, -0.1086],\n",
      "         [-0.1284, -0.0191,  0.0808],\n",
      "         [-0.0156, -0.0207, -0.0257],\n",
      "         [ 0.0294,  0.0906, -0.0216],\n",
      "         [-0.0782, -0.0501, -0.1135],\n",
      "         [-0.1305,  0.0988, -0.1410],\n",
      "         [-0.0032, -0.0138,  0.1342],\n",
      "         [-0.0483,  0.0552, -0.0743],\n",
      "         [ 0.0339,  0.0162, -0.1367],\n",
      "         [-0.1112,  0.0808, -0.0966],\n",
      "         [-0.1011, -0.0609,  0.0561]],\n",
      "\n",
      "        [[ 0.1385,  0.1217, -0.0197],\n",
      "         [-0.1433, -0.0258, -0.1181],\n",
      "         [ 0.0748,  0.0981, -0.0615],\n",
      "         [-0.0648, -0.0533,  0.0766],\n",
      "         [-0.0933, -0.0703, -0.0527],\n",
      "         [-0.0674, -0.0665, -0.1403],\n",
      "         [-0.0388,  0.0205,  0.1310],\n",
      "         [-0.1234, -0.0282, -0.0157],\n",
      "         [ 0.1089,  0.1058,  0.0908],\n",
      "         [-0.0165,  0.0602, -0.0992],\n",
      "         [-0.0588, -0.1234, -0.0583],\n",
      "         [ 0.0669,  0.0952,  0.0012],\n",
      "         [-0.0146,  0.0745,  0.0460],\n",
      "         [-0.1087,  0.0184,  0.0595],\n",
      "         [-0.1322, -0.1215, -0.0091],\n",
      "         [-0.0252, -0.0220, -0.1007]],\n",
      "\n",
      "        [[-0.0982,  0.1169,  0.0933],\n",
      "         [-0.0875,  0.0158,  0.0307],\n",
      "         [-0.0999, -0.0656, -0.1033],\n",
      "         [-0.0348, -0.0603, -0.1047],\n",
      "         [-0.0342,  0.0823,  0.1048],\n",
      "         [-0.0138, -0.0642, -0.0760],\n",
      "         [-0.1065, -0.0205, -0.0791],\n",
      "         [-0.0459,  0.1413, -0.0827],\n",
      "         [-0.0751, -0.0046,  0.0241],\n",
      "         [-0.1135,  0.1251,  0.0232],\n",
      "         [-0.0934, -0.0481, -0.1284],\n",
      "         [-0.0021, -0.0561,  0.0570],\n",
      "         [-0.1344,  0.0355, -0.0720],\n",
      "         [-0.0253,  0.0840,  0.0421],\n",
      "         [ 0.0068,  0.0308, -0.1347],\n",
      "         [ 0.0942,  0.0530,  0.0104]],\n",
      "\n",
      "        [[-0.1016,  0.0139, -0.0913],\n",
      "         [-0.1218, -0.0173,  0.1265],\n",
      "         [ 0.0883,  0.0660,  0.0298],\n",
      "         [ 0.0801,  0.1393, -0.0912],\n",
      "         [ 0.0842,  0.1401, -0.0228],\n",
      "         [-0.0995,  0.0290, -0.0444],\n",
      "         [-0.0559, -0.0646,  0.0880],\n",
      "         [-0.0396, -0.0736,  0.0428],\n",
      "         [-0.1345,  0.0059,  0.0634],\n",
      "         [ 0.1363,  0.0166, -0.0824],\n",
      "         [-0.0213,  0.0133,  0.0088],\n",
      "         [ 0.1148,  0.0164, -0.1272],\n",
      "         [ 0.0778,  0.1183,  0.0377],\n",
      "         [-0.0901, -0.0318,  0.0382],\n",
      "         [ 0.1104, -0.0122, -0.0199],\n",
      "         [-0.1406,  0.0632,  0.0385]],\n",
      "\n",
      "        [[ 0.0566, -0.0787,  0.0595],\n",
      "         [-0.0483,  0.0967,  0.0010],\n",
      "         [ 0.0647,  0.0945, -0.0372],\n",
      "         [-0.1210, -0.0171, -0.0669],\n",
      "         [ 0.0775,  0.0723, -0.1309],\n",
      "         [ 0.0136,  0.0707,  0.0157],\n",
      "         [-0.1405,  0.0355, -0.0359],\n",
      "         [ 0.1223, -0.1279,  0.1276],\n",
      "         [-0.0263, -0.0225,  0.0851],\n",
      "         [ 0.0032, -0.0126, -0.1087],\n",
      "         [ 0.0311,  0.0188, -0.0002],\n",
      "         [ 0.1290, -0.0708,  0.0835],\n",
      "         [ 0.0311, -0.1101, -0.0017],\n",
      "         [ 0.0616,  0.1287,  0.1094],\n",
      "         [ 0.0758, -0.0643,  0.0101],\n",
      "         [ 0.1156, -0.0116,  0.0083]],\n",
      "\n",
      "        [[ 0.1006,  0.0834, -0.0279],\n",
      "         [ 0.0318,  0.0448,  0.1004],\n",
      "         [-0.1047, -0.0681,  0.0713],\n",
      "         [-0.1306, -0.1153, -0.0660],\n",
      "         [ 0.1188,  0.1155, -0.0534],\n",
      "         [ 0.1082,  0.0012, -0.0734],\n",
      "         [-0.0430,  0.1280, -0.1281],\n",
      "         [ 0.0944, -0.0665,  0.0016],\n",
      "         [-0.1401, -0.0696, -0.1007],\n",
      "         [ 0.1378,  0.0356, -0.0791],\n",
      "         [-0.1103,  0.0251, -0.0560],\n",
      "         [-0.0075, -0.0728,  0.0344],\n",
      "         [-0.0458,  0.0755,  0.0479],\n",
      "         [ 0.1345, -0.1012, -0.0003],\n",
      "         [ 0.0062,  0.0851, -0.0463],\n",
      "         [-0.0793,  0.0977, -0.0365]],\n",
      "\n",
      "        [[-0.1205,  0.0428, -0.1134],\n",
      "         [-0.1078, -0.0502, -0.0744],\n",
      "         [-0.0865,  0.0175, -0.0431],\n",
      "         [ 0.0984, -0.0841,  0.1210],\n",
      "         [-0.1391, -0.1437, -0.1390],\n",
      "         [ 0.0326,  0.0117,  0.0349],\n",
      "         [ 0.1172,  0.1255,  0.1404],\n",
      "         [ 0.1428, -0.0460,  0.1318],\n",
      "         [-0.0541, -0.1197,  0.0863],\n",
      "         [ 0.0692,  0.0460,  0.0458],\n",
      "         [ 0.0366, -0.0335, -0.0999],\n",
      "         [-0.0299,  0.1094,  0.0592],\n",
      "         [ 0.0864,  0.0233,  0.0857],\n",
      "         [ 0.0280,  0.1164, -0.0875],\n",
      "         [-0.1378, -0.0554, -0.0470],\n",
      "         [-0.0826,  0.1186,  0.1380]],\n",
      "\n",
      "        [[-0.1413, -0.1263,  0.0489],\n",
      "         [ 0.0318, -0.0694,  0.1035],\n",
      "         [ 0.0378,  0.0427, -0.0405],\n",
      "         [ 0.0976,  0.1286,  0.0075],\n",
      "         [-0.0516,  0.0747,  0.0680],\n",
      "         [ 0.0392, -0.1286, -0.0826],\n",
      "         [ 0.0031,  0.0958, -0.0525],\n",
      "         [-0.0221, -0.1076, -0.0376],\n",
      "         [ 0.1085,  0.0723,  0.0612],\n",
      "         [ 0.0848, -0.0915,  0.0363],\n",
      "         [ 0.0826, -0.0306, -0.0666],\n",
      "         [ 0.0877, -0.0423,  0.0362],\n",
      "         [ 0.0849, -0.1150,  0.0797],\n",
      "         [-0.1022,  0.0371, -0.1098],\n",
      "         [-0.1373,  0.0563,  0.0055],\n",
      "         [ 0.1382,  0.0364, -0.0091]]], requires_grad=True)\n",
      "Output =  torch.Size([1, 16, 4])\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import torch\n",
    "\n",
    "# Describe the input variable\n",
    "inp = torch.ones(1,16,6)\n",
    "\n",
    "# Print input\n",
    "print(\"Input = \",inp)\n",
    "\n",
    "m = torch.nn.Conv1d(in_channels = 16, out_channels = 16, kernel_size = 3)\n",
    "\n",
    "# Print the parameter list\n",
    "print(\"net = \",m)\n",
    "print(\"Parameters = \",list(m.parameters()))\n",
    "# Print the weight\n",
    "print(\"Weight = \",m.weight)\n",
    "\n",
    "\n",
    "out = m(inp)\n",
    "\n",
    "print(\"Output = \",out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_egg_processed_t(ruta_evento):\n",
    "    # Cargar datos desde el archivo .mat\n",
    "    mat_data = loadmat(ruta_evento)\n",
    "\n",
    "    # Obtener 'eeg_processed' del diccionario cargado\n",
    "    eeg_processed = mat_data.get('eeg_processed')\n",
    "    eeg_processed_tensor = tf.convert_to_tensor(eeg_processed)\n",
    "\n",
    "    return eeg_processed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_sujxrun(ruta, sujeto):\n",
    "    eventos_por_mark = {}\n",
    "\n",
    "    for subject in os.listdir(ruta):\n",
    "        if f\"Subject {sujeto}\" in subject:\n",
    "            ruta_subj = os.path.join(ruta, subject)\n",
    "            archivos_suj = os.listdir(ruta_subj)\n",
    "\n",
    "            for run in range(1, 7):  # Iterar sobre los 6 runs\n",
    "                for suj in archivos_suj:\n",
    "                    if f\"run_{run}\" in suj:  # Corregido para iterar sobre todos los runs\n",
    "                        ruta_suj = os.path.join(ruta_subj, suj)\n",
    "                        archivos_mark = os.listdir(ruta_suj)\n",
    "\n",
    "                        for mark in archivos_mark:\n",
    "                            ruta_mark = os.path.join(ruta_suj, mark)\n",
    "                            archivos_event = os.listdir(ruta_mark)\n",
    "\n",
    "                            for event in archivos_event:\n",
    "                                ruta_evento = os.path.join(ruta_mark, event)\n",
    "\n",
    "                                eeg_processed = get_egg_processed_t(ruta_evento)\n",
    "                                if eeg_processed.shape != (0, 16):\n",
    "                                    if mark not in eventos_por_mark:\n",
    "                                        eventos_por_mark[mark] = []\n",
    "                                    eventos_por_mark[mark].append(eeg_processed)\n",
    "                                    \n",
    "   \n",
    "    return eventos_por_mark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Marker_1': <tf.Tensor: shape=(63, 385, 16), dtype=float64, numpy=\n",
      "array([[[-0.7265575 , -0.65101729, -1.        , ..., -0.50346511,\n",
      "         -0.32013615, -0.59905516],\n",
      "        [-0.67816966, -0.5985542 , -0.56414983, ..., -0.28778956,\n",
      "         -0.09780727, -0.67023779],\n",
      "        [-0.64119087, -0.58064911, -0.16354134, ...,  0.06860901,\n",
      "          0.20599897, -0.55113152],\n",
      "        ...,\n",
      "        [-0.14065726,  0.2359265 ,  0.81640086, ...,  0.27196593,\n",
      "          0.39501937,  0.85777496],\n",
      "        [-0.1461181 ,  0.22426275,  0.60313194, ...,  0.45532535,\n",
      "          0.5060532 ,  0.9429678 ],\n",
      "        [-0.32565557,  0.05800861, -0.18401914, ...,  0.34971831,\n",
      "          0.15307825,  0.95560016]],\n",
      "\n",
      "       [[ 0.52829984, -0.75924963, -0.12009981, ...,  0.13848112,\n",
      "         -0.95876275, -0.23228808],\n",
      "        [ 0.58500486, -0.65135342, -0.58990202, ...,  0.25117881,\n",
      "         -0.61907484,  0.09356379],\n",
      "        [ 0.64733311, -0.52450758, -0.32888821, ...,  0.40487155,\n",
      "         -0.25194263,  0.41252575],\n",
      "        ...,\n",
      "        [-0.62898839,  0.1398107 ,  0.34746827, ..., -0.89976146,\n",
      "         -0.26786495, -0.71149954],\n",
      "        [-0.693175  ,  0.12708773,  0.6826344 , ..., -0.8600638 ,\n",
      "         -0.2594464 , -0.65002733],\n",
      "        [-1.        , -0.09184797,  0.26584414, ..., -0.8970551 ,\n",
      "         -0.40183441, -0.67116057]],\n",
      "\n",
      "       [[-0.45585639,  0.00199508, -1.        , ..., -0.65417538,\n",
      "         -0.56656892, -0.17880674],\n",
      "        [-0.45649706,  0.05906948, -0.07339887, ..., -0.48006568,\n",
      "         -0.22081532, -0.43847434],\n",
      "        [-0.41225228,  0.1413835 , -0.10132114, ..., -0.31713824,\n",
      "          0.03898659, -0.37736832],\n",
      "        ...,\n",
      "        [-0.80171564, -0.74387034,  0.12817464, ...,  0.47087216,\n",
      "          0.45513221,  0.23370951],\n",
      "        [-0.81361944, -0.76423274, -0.31703053, ...,  0.20570523,\n",
      "          0.4188673 ,  0.08637545],\n",
      "        [-0.74924188, -0.69219813,  0.08047193, ..., -0.00630357,\n",
      "          0.35686706, -0.06883427]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.60729806, -1.        , -1.        , ..., -1.        ,\n",
      "         -1.        , -1.        ],\n",
      "        [-0.35756112, -0.66542654, -0.60265398, ..., -0.74514572,\n",
      "         -0.63689037, -0.73346674],\n",
      "        [-0.27278878, -0.53301191, -0.44575137, ..., -0.60388728,\n",
      "         -0.4601116 , -0.59648344],\n",
      "        ...,\n",
      "        [ 0.46664286,  0.47003514,  0.64235272, ...,  0.78664622,\n",
      "          0.81884454,  0.77194404],\n",
      "        [ 0.32824328,  0.34619718,  0.50556387, ...,  0.72423972,\n",
      "          0.67890887,  0.7260899 ],\n",
      "        [ 0.03168595,  0.1255193 ,  0.24847523, ...,  0.55494452,\n",
      "          0.46690592,  0.59119401]],\n",
      "\n",
      "       [[-0.57665888, -0.70049084, -0.73482115, ..., -0.4107113 ,\n",
      "         -0.33699694, -0.0414159 ],\n",
      "        [-0.61348415, -0.6909277 , -0.74074365, ..., -0.44901209,\n",
      "         -0.34851552,  0.01898135],\n",
      "        [-0.38089465, -0.47397962, -0.45963737, ..., -0.31796175,\n",
      "         -0.27936475,  0.18414288],\n",
      "        ...,\n",
      "        [-0.08910813,  0.1125064 ,  0.2118211 , ...,  0.30296928,\n",
      "          0.49937434, -0.10747869],\n",
      "        [-0.04664981,  0.09950011,  0.24242258, ...,  0.39391076,\n",
      "          0.58451973, -0.01410274],\n",
      "        [-0.25050616, -0.18804726, -0.13957993, ...,  0.32358565,\n",
      "          0.47948846, -0.02925148]],\n",
      "\n",
      "       [[-0.80659673, -0.64357718, -0.92208977, ..., -0.16055683,\n",
      "         -0.31235555,  0.1224409 ],\n",
      "        [-0.49146679, -0.27975947, -0.40500562, ...,  0.08535332,\n",
      "          0.03559016,  0.28857153],\n",
      "        [-0.37055724, -0.17095149, -0.22502993, ...,  0.17537641,\n",
      "          0.1999726 ,  0.35357769],\n",
      "        ...,\n",
      "        [ 0.18019947,  0.2670683 ,  0.36785679, ...,  0.45243296,\n",
      "          0.65172037,  0.61225525],\n",
      "        [-0.14322361, -0.08758877, -0.0185289 , ...,  0.1962263 ,\n",
      "          0.35623869,  0.3731666 ],\n",
      "        [-0.66272295, -0.64093176, -0.65676956, ..., -0.25439485,\n",
      "         -0.22076456, -0.06642735]]])>, 'Marker_2': <tf.Tensor: shape=(80, 385, 16), dtype=float64, numpy=\n",
      "array([[[ 0.10996718, -0.46860781,  0.38054546, ..., -0.82349113,\n",
      "         -0.85982885, -0.90093929],\n",
      "        [-0.21428874, -0.64926251, -0.26451307, ..., -0.95899416,\n",
      "         -0.99929309, -1.        ],\n",
      "        [-0.45961105, -0.79450163, -0.88909312, ..., -1.        ,\n",
      "         -1.        , -0.97470994],\n",
      "        ...,\n",
      "        [-0.65699887,  0.444851  ,  0.03771358, ...,  0.15519976,\n",
      "          0.56602045,  0.48114631],\n",
      "        [-0.78825596,  0.38199074,  0.19516869, ...,  0.11424667,\n",
      "          0.47707669,  0.40076135],\n",
      "        [-1.        ,  0.25787066,  1.        , ...,  0.09790446,\n",
      "          0.24029741,  0.31881469]],\n",
      "\n",
      "       [[ 0.67919915,  0.85334893,  0.64544647, ...,  0.92452582,\n",
      "          0.59887071,  0.16244582],\n",
      "        [ 0.81535555,  0.93623471, -0.14094072, ...,  0.78967342,\n",
      "          0.68778708,  0.06121811],\n",
      "        [ 0.94467644,  1.        ,  0.16571004, ...,  0.66190766,\n",
      "          0.54754285, -0.08728051],\n",
      "        ...,\n",
      "        [-0.51245683, -0.57483287,  0.24163314, ...,  0.08318537,\n",
      "         -0.72058085, -0.14877088],\n",
      "        [-0.57928725, -0.59702691,  0.54706656, ...,  0.07417025,\n",
      "         -0.7850772 , -0.21397073],\n",
      "        [-0.72734536, -0.69172564, -0.195681  , ..., -0.04332139,\n",
      "         -0.78757414, -0.2856678 ]],\n",
      "\n",
      "       [[-0.67494514, -0.54064121, -0.99801377, ..., -0.1502896 ,\n",
      "         -0.38572913, -0.47464982],\n",
      "        [-0.5612774 , -0.27953456, -0.80627314, ..., -0.01185492,\n",
      "         -0.23095473, -0.34138398],\n",
      "        [-0.44093049, -0.01790718, -0.17766376, ...,  0.08512859,\n",
      "         -0.13763801, -0.38505474],\n",
      "        ...,\n",
      "        [-0.10617995,  0.25578217,  0.60854419, ...,  0.57273826,\n",
      "          0.18285594,  0.64589928],\n",
      "        [-0.15147931,  0.20114662,  0.68915043, ...,  0.51859901,\n",
      "          0.12956821,  0.51441446],\n",
      "        [-0.19470635,  0.06810828, -0.12290859, ...,  0.41200528,\n",
      "          0.06278111,  0.43595164]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.61073812, -0.41224466, -0.46662927, ..., -0.48807701,\n",
      "         -0.17861029, -0.46529225],\n",
      "        [-0.76506528, -0.62041207, -0.75470014, ..., -0.59907719,\n",
      "         -0.27705148, -0.50867398],\n",
      "        [-0.90997652, -0.78056731, -0.96964882, ..., -0.7225687 ,\n",
      "         -0.37986485, -0.58848464],\n",
      "        ...,\n",
      "        [ 0.34566415,  0.05313574,  0.32321886, ...,  0.44748806,\n",
      "          0.35784715,  0.56074156],\n",
      "        [ 0.36137344,  0.11697646,  0.39011144, ...,  0.51829701,\n",
      "          0.46141809,  0.6118803 ],\n",
      "        [ 0.56301479,  0.41427549,  0.70200628, ...,  0.74685326,\n",
      "          0.72801393,  0.75629835]],\n",
      "\n",
      "       [[-0.27968613, -0.03486046, -0.19964421, ..., -0.41352631,\n",
      "         -0.57227549, -0.15911647],\n",
      "        [-0.46161255, -0.2626136 , -0.52270615, ..., -0.60335106,\n",
      "         -0.75556783, -0.27654333],\n",
      "        [-0.47782335, -0.30735729, -0.61654043, ..., -0.71998192,\n",
      "         -0.88136756, -0.39460438],\n",
      "        ...,\n",
      "        [ 0.12263934,  0.24968415,  0.15665637, ...,  0.42410048,\n",
      "          0.50989603,  0.54665131],\n",
      "        [ 0.44252467,  0.5425664 ,  0.48172754, ...,  0.61558975,\n",
      "          0.59617336,  0.69825878],\n",
      "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
      "          0.80089099,  1.        ]],\n",
      "\n",
      "       [[-0.00872607, -0.21940158, -0.2410736 , ...,  0.57847779,\n",
      "          0.26444992,  0.39328522],\n",
      "        [ 0.07288384, -0.08791464,  0.0284279 , ...,  0.67184621,\n",
      "          0.4030007 ,  0.48112535],\n",
      "        [ 0.30843929,  0.18290424,  0.45470354, ...,  0.82379497,\n",
      "          0.62014845,  0.62694387],\n",
      "        ...,\n",
      "        [ 0.19561439,  0.3684372 ,  0.24646316, ..., -0.10388655,\n",
      "          0.06276183,  0.07310978],\n",
      "        [ 0.33665936,  0.43570305,  0.29048535, ...,  0.09725413,\n",
      "          0.28955785,  0.2584033 ],\n",
      "        [ 0.12368838,  0.11561405, -0.26844265, ...,  0.06869982,\n",
      "          0.22760508,  0.21086425]]])>, 'Marker_3': <tf.Tensor: shape=(83, 385, 16), dtype=float64, numpy=\n",
      "array([[[-7.16472965e-01, -7.29519050e-01, -5.03354257e-01, ...,\n",
      "         -8.95600231e-01, -9.34571966e-01, -9.55095711e-01],\n",
      "        [-7.75376622e-01, -7.66434643e-01, -3.22762623e-01, ...,\n",
      "         -8.04986481e-01, -7.18211288e-01, -8.24554102e-01],\n",
      "        [-8.95190173e-01, -8.76028120e-01, -6.70307511e-01, ...,\n",
      "         -8.38248735e-01, -6.64102545e-01, -7.86819590e-01],\n",
      "        ...,\n",
      "        [-6.74132670e-02, -4.00564971e-01,  3.71242802e-01, ...,\n",
      "          2.43589312e-01,  8.94102154e-01,  4.58564011e-01],\n",
      "        [-8.69345480e-02, -3.92580918e-01,  9.73318988e-02, ...,\n",
      "          1.66979511e-01,  3.80744708e-01,  3.87830048e-01],\n",
      "        [ 1.03280973e-01, -1.92022063e-01,  4.38801212e-01, ...,\n",
      "          1.14975083e-01, -9.05129290e-01,  3.29608187e-01]],\n",
      "\n",
      "       [[ 6.56009654e-01,  7.87692334e-01,  4.76277524e-01, ...,\n",
      "          5.48457173e-01,  4.25603410e-01,  4.31391893e-01],\n",
      "        [ 7.63127982e-01,  9.26882113e-01, -3.88498539e-01, ...,\n",
      "          7.28177507e-01,  6.44443938e-01,  6.81426580e-01],\n",
      "        [ 7.22762525e-01,  9.61377801e-01, -3.83856158e-01, ...,\n",
      "          8.85950873e-01,  7.59866830e-01,  8.55209356e-01],\n",
      "        ...,\n",
      "        [ 2.12740888e-01, -7.28876117e-02, -2.77738499e-01, ...,\n",
      "         -2.42979331e-01,  1.66549437e-01, -2.35085290e-01],\n",
      "        [ 2.89950627e-01,  3.95072051e-02,  4.27264126e-01, ...,\n",
      "         -2.09035565e-01,  7.11193670e-02, -2.41655137e-01],\n",
      "        [ 5.00736966e-01,  2.64366860e-01,  1.00000000e+00, ...,\n",
      "         -5.89921803e-02,  1.26353231e-01, -2.34573155e-01]],\n",
      "\n",
      "       [[-7.91023690e-02, -4.33618160e-01, -1.00000000e+00, ...,\n",
      "          3.97920702e-02,  1.38772059e-01, -3.19072877e-01],\n",
      "        [-6.41174463e-02, -4.20437850e-01, -3.05160195e-02, ...,\n",
      "          4.06831477e-04,  1.93286475e-02, -4.10191714e-01],\n",
      "        [-3.67487456e-02, -4.23514802e-01,  5.08380112e-01, ...,\n",
      "          3.84133298e-02,  3.44538395e-02, -3.08348669e-01],\n",
      "        ...,\n",
      "        [ 1.08560453e-01,  5.94068933e-01,  1.00000000e+00, ...,\n",
      "         -1.69036797e-01, -4.40722756e-02,  3.61583244e-01],\n",
      "        [ 3.04589481e-01,  7.06838613e-01,  5.74921361e-01, ...,\n",
      "         -5.45077088e-02,  2.24115719e-02,  5.49717287e-01],\n",
      "        [ 5.74751284e-01,  8.91766702e-01, -4.10590453e-01, ...,\n",
      "          2.32948801e-02,  4.06360111e-01,  7.78997830e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-7.94969473e-01, -6.62963443e-01, -5.44332525e-01, ...,\n",
      "         -1.89801697e-01, -8.25387148e-01, -5.25484451e-02],\n",
      "        [-5.89557490e-01, -4.64198935e-01, -2.96636216e-01, ...,\n",
      "         -1.29983058e-01, -5.59678729e-01,  7.82481784e-02],\n",
      "        [-5.49629986e-01, -4.62425744e-01, -3.30670365e-01, ...,\n",
      "         -1.52625923e-01, -4.37602648e-01,  1.30424213e-01],\n",
      "        ...,\n",
      "        [-4.63743699e-01, -2.78044173e-01,  8.32993265e-02, ...,\n",
      "         -3.19684469e-05, -4.21116002e-01, -4.80224209e-01],\n",
      "        [-6.15365759e-01, -4.78687438e-01, -1.51479062e-01, ...,\n",
      "         -1.27099302e-01, -5.15058374e-01, -6.49366706e-01],\n",
      "        [-7.36228935e-01, -6.06404693e-01, -2.75363860e-01, ...,\n",
      "         -2.26831495e-01, -5.93362100e-01, -8.05633610e-01]],\n",
      "\n",
      "       [[-4.94430628e-01, -8.04239336e-01, -6.37229375e-01, ...,\n",
      "         -3.64718453e-01,  8.76307316e-02, -1.31942196e-01],\n",
      "        [-7.93970669e-01, -1.00000000e+00, -9.18379921e-01, ...,\n",
      "         -4.26686371e-01, -2.39546160e-02, -1.45006375e-01],\n",
      "        [-8.16931625e-01, -8.92965330e-01, -7.93384832e-01, ...,\n",
      "         -3.63082038e-01,  6.60247183e-03, -7.20572303e-02],\n",
      "        ...,\n",
      "        [-4.35504837e-01, -6.69725335e-01, -3.52795489e-01, ...,\n",
      "         -6.42844642e-01, -8.13577925e-01, -6.97509979e-01],\n",
      "        [-2.04136293e-01, -3.94304583e-01,  2.17978555e-02, ...,\n",
      "         -5.16406604e-01, -7.28986879e-01, -6.17838213e-01],\n",
      "        [ 3.07419840e-02, -1.70529209e-01,  2.98777274e-01, ...,\n",
      "         -4.32362819e-01, -6.85486318e-01, -5.79065753e-01]],\n",
      "\n",
      "       [[-6.24611716e-01, -4.37334123e-01, -9.45382980e-01, ...,\n",
      "         -7.44406980e-01, -7.85417174e-01, -7.83395667e-01],\n",
      "        [-6.30968165e-01, -3.61058581e-01, -6.34771023e-01, ...,\n",
      "         -7.77536893e-01, -8.19082012e-01, -8.80627022e-01],\n",
      "        [-6.22481332e-01, -2.92971145e-01, -3.84543084e-01, ...,\n",
      "         -7.42621657e-01, -7.80132064e-01, -8.54143233e-01],\n",
      "        ...,\n",
      "        [-2.88050049e-02, -1.88903421e-01,  8.26672726e-02, ...,\n",
      "          3.03342341e-01,  1.35308254e-01,  1.39208897e-01],\n",
      "        [-2.55318168e-01, -4.34796117e-01, -2.56721472e-01, ...,\n",
      "          1.27553138e-01, -6.07745350e-02, -6.87006833e-02],\n",
      "        [-6.93065498e-01, -9.25007787e-01, -9.37404539e-01, ...,\n",
      "         -2.68631909e-01, -2.67370965e-01, -4.73682481e-01]]])>, 'Marker_4': <tf.Tensor: shape=(75, 385, 16), dtype=float64, numpy=\n",
      "array([[[-8.64980059e-03, -6.42170818e-01, -4.23941995e-02, ...,\n",
      "         -1.76073334e-01, -1.72021315e-01, -9.03019752e-01],\n",
      "        [-3.43873050e-02, -6.81315954e-01, -4.56933404e-01, ...,\n",
      "         -1.65742208e-01, -1.86784582e-01, -8.98213193e-01],\n",
      "        [ 6.63382049e-02, -6.09821369e-01, -8.81624368e-01, ...,\n",
      "         -1.07334226e-01, -6.54382708e-02, -8.06136971e-01],\n",
      "        ...,\n",
      "        [ 2.73420581e-01,  4.93410340e-01, -1.01365735e-01, ...,\n",
      "         -7.04264001e-02,  4.46293001e-01,  5.38017982e-01],\n",
      "        [ 4.38517457e-01,  6.94547102e-01,  2.07182380e-01, ...,\n",
      "          1.59397222e-01,  6.56703235e-01,  6.95454704e-01],\n",
      "        [ 5.95685252e-01,  8.51912801e-01,  1.00000000e+00, ...,\n",
      "          6.70371080e-01,  1.00000000e+00,  1.00000000e+00]],\n",
      "\n",
      "       [[ 6.75514373e-01, -1.16125332e-01,  4.81834659e-01, ...,\n",
      "          3.94358367e-01,  3.13466787e-01, -1.96318707e-01],\n",
      "        [ 1.93349145e-01, -4.50311284e-01, -6.60708977e-02, ...,\n",
      "          1.31824934e-01,  2.39398483e-01, -1.94847305e-01],\n",
      "        [-6.42272884e-02, -6.16171942e-01, -5.93844940e-01, ...,\n",
      "         -1.48578803e-01, -5.10610307e-02, -3.59019194e-01],\n",
      "        ...,\n",
      "        [ 2.09144695e-01,  6.59529092e-01, -2.20267558e-01, ...,\n",
      "          3.94668057e-01, -6.23265703e-02, -3.96860657e-02],\n",
      "        [ 1.58270236e-01,  7.28866232e-01,  1.01366141e-01, ...,\n",
      "          3.73836519e-01, -1.44005707e-01, -1.61057448e-01],\n",
      "        [ 1.79290013e-01,  8.52599211e-01,  1.00000000e+00, ...,\n",
      "          5.20448894e-01,  3.96370448e-03, -7.83006992e-02]],\n",
      "\n",
      "       [[-3.57413721e-01,  6.87292705e-02,  6.14164743e-01, ...,\n",
      "         -6.96916679e-02,  1.35327016e-01, -9.37801542e-01],\n",
      "        [-4.22596211e-01, -9.20571257e-02,  5.40639541e-03, ...,\n",
      "         -1.14398342e-01, -8.95735761e-02, -7.57206126e-01],\n",
      "        [-4.60355775e-01, -1.89635970e-01, -6.18395201e-01, ...,\n",
      "         -2.18502848e-01, -3.10573019e-01, -6.88485547e-01],\n",
      "        ...,\n",
      "        [-1.37603524e-01, -3.19868770e-02, -4.09211576e-01, ...,\n",
      "         -5.95868566e-01, -4.80422769e-01,  1.94384716e-01],\n",
      "        [-1.07727489e-01, -2.29732248e-02, -4.37194967e-02, ...,\n",
      "         -6.82656027e-01, -4.53565667e-01,  1.55667418e-01],\n",
      "        [-4.58044304e-02,  1.38567957e-02,  1.00000000e+00, ...,\n",
      "         -5.86925851e-01, -2.66150273e-01,  2.43428493e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-4.72023133e-01, -3.99181570e-01, -4.41552890e-01, ...,\n",
      "         -4.13611896e-01, -8.53690748e-01, -8.04228388e-01],\n",
      "        [-6.24982167e-01, -6.37803750e-01, -7.01543017e-01, ...,\n",
      "         -5.48632880e-01, -9.21184584e-01, -8.82067153e-01],\n",
      "        [-7.41590523e-01, -8.01880728e-01, -8.90937479e-01, ...,\n",
      "         -6.83035766e-01, -1.00000000e+00, -9.70416866e-01],\n",
      "        ...,\n",
      "        [ 6.86060388e-01,  6.82977780e-01,  6.60834298e-01, ...,\n",
      "          7.10833061e-01,  7.38351977e-01,  6.90272866e-01],\n",
      "        [ 6.97609624e-01,  7.52541019e-01,  7.37291168e-01, ...,\n",
      "          7.83856677e-01,  7.76663692e-01,  7.64146496e-01],\n",
      "        [ 8.27165727e-01,  9.99438526e-01,  1.00000000e+00, ...,\n",
      "          1.00000000e+00,  1.00000000e+00,  1.00000000e+00]],\n",
      "\n",
      "       [[-1.00000000e+00, -1.00000000e+00, -1.00000000e+00, ...,\n",
      "         -7.14174578e-01, -6.70494512e-01, -8.03511550e-01],\n",
      "        [-7.49649696e-01, -8.04403088e-01, -7.37616669e-01, ...,\n",
      "         -5.74843376e-01, -5.43573931e-01, -7.57097655e-01],\n",
      "        [-6.59805502e-01, -7.95127534e-01, -7.25594224e-01, ...,\n",
      "         -5.33793375e-01, -5.13075239e-01, -7.43220409e-01],\n",
      "        ...,\n",
      "        [ 8.77086318e-01,  8.06773862e-01,  7.77526009e-01, ...,\n",
      "          8.06592422e-01,  1.00000000e+00,  8.02741171e-01],\n",
      "        [ 6.90788747e-01,  5.96762991e-01,  5.05090188e-01, ...,\n",
      "          7.32434081e-01,  8.54076727e-01,  7.87756419e-01],\n",
      "        [ 4.78445856e-01,  3.92345883e-01,  2.25210710e-01, ...,\n",
      "          6.67585512e-01,  7.39276782e-01,  8.11289429e-01]],\n",
      "\n",
      "       [[ 9.91823469e-02,  9.72021351e-02, -2.68189629e-01, ...,\n",
      "         -6.55942994e-02, -1.23664723e-01, -4.24511776e-04],\n",
      "        [-3.21524437e-01, -4.01845586e-01, -6.81720756e-01, ...,\n",
      "         -5.14608743e-01, -4.19851381e-01, -4.14940353e-01],\n",
      "        [-5.26121564e-01, -6.26526684e-01, -8.37147838e-01, ...,\n",
      "         -8.24402880e-01, -7.27144450e-01, -7.33481032e-01],\n",
      "        ...,\n",
      "        [ 5.32769735e-01,  5.18644588e-01,  5.52729579e-01, ...,\n",
      "          5.60720696e-01,  5.53358401e-01,  6.93156173e-01],\n",
      "        [ 7.62252003e-01,  7.73162440e-01,  7.93498930e-01, ...,\n",
      "          7.73235056e-01,  7.67944816e-01,  8.71019971e-01],\n",
      "        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
      "          1.00000000e+00,  1.00000000e+00,  1.00000000e+00]]])>, 'Marker_5': <tf.Tensor: shape=(78, 385, 16), dtype=float64, numpy=\n",
      "array([[[ 0.35980699,  0.5674511 , -0.11498436, ..., -0.84035802,\n",
      "         -0.12789026, -0.96611502],\n",
      "        [ 0.09041242,  0.28630299, -0.2346392 , ..., -0.8735675 ,\n",
      "         -0.0318351 , -0.94532455],\n",
      "        [-0.13626412,  0.02874803, -0.7128828 , ..., -0.94958115,\n",
      "          0.00952206, -0.93192451],\n",
      "        ...,\n",
      "        [-0.66822415, -0.50271481,  0.20509081, ...,  0.23358881,\n",
      "          0.0356946 ,  0.64925377],\n",
      "        [-0.67199328, -0.47943894,  0.16648159, ...,  0.15427355,\n",
      "         -0.04625925,  0.5592813 ],\n",
      "        [-0.65270292, -0.50887687,  0.76340494, ...,  0.13045549,\n",
      "         -0.27922455,  0.45785283]],\n",
      "\n",
      "       [[-0.09015382, -0.22057112, -1.        , ..., -0.44112385,\n",
      "         -0.13087211, -0.40003355],\n",
      "        [-0.16137195, -0.24979543, -0.42673543, ..., -0.13871312,\n",
      "          0.01047009, -0.07040298],\n",
      "        [-0.31636447, -0.41585614,  0.03151709, ...,  0.11158464,\n",
      "          0.20944345,  0.17462796],\n",
      "        ...,\n",
      "        [-0.28199426, -0.19024025,  0.59878164, ..., -0.34072414,\n",
      "         -0.87625707, -0.09717518],\n",
      "        [-0.44767942, -0.37508172,  0.19542887, ..., -0.37349472,\n",
      "         -0.80718764, -0.01906915],\n",
      "        [-0.65812738, -0.6108933 , -0.77574672, ..., -0.56736952,\n",
      "         -0.84853147, -0.03823415]],\n",
      "\n",
      "       [[ 0.33500198, -0.23196744,  0.78252139, ...,  0.22472094,\n",
      "          0.11765842, -0.19189393],\n",
      "        [ 0.26615601, -0.32271385,  0.20903013, ...,  0.21366997,\n",
      "          0.22612971, -0.05291106],\n",
      "        [ 0.25103978, -0.40905005, -0.50645428, ...,  0.06000197,\n",
      "          0.19424477, -0.06126693],\n",
      "        ...,\n",
      "        [ 0.14683652,  0.43432559, -0.05943397, ...,  0.12791317,\n",
      "          0.4427846 ,  0.47926318],\n",
      "        [ 0.28348019,  0.49971523, -0.02994   , ...,  0.12620782,\n",
      "          0.49587404,  0.5000826 ],\n",
      "        [ 0.47650197,  0.58225058,  0.91639905, ...,  0.17416855,\n",
      "          0.44761997,  0.42443424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.68872199, -0.48660404, -0.77023244, ..., -0.36317551,\n",
      "         -0.55094213, -0.66820975],\n",
      "        [-0.42110514, -0.10480885, -0.38412647, ..., -0.16737216,\n",
      "         -0.41038608, -0.55443125],\n",
      "        [-0.19447673,  0.15303258, -0.0973234 , ..., -0.02236338,\n",
      "         -0.31733026, -0.48567194],\n",
      "        ...,\n",
      "        [ 0.9617957 ,  0.98158903,  1.        , ...,  0.91554662,\n",
      "          0.93532299,  0.90878171],\n",
      "        [ 1.        ,  0.94675948,  0.93720096, ...,  0.96951143,\n",
      "          1.        ,  0.95624612],\n",
      "        [ 0.73391294,  0.53535542,  0.51461711, ...,  0.76201472,\n",
      "          0.70089845,  0.7424163 ]],\n",
      "\n",
      "       [[-0.39960717, -0.123465  , -0.18886497, ..., -0.27530618,\n",
      "         -0.27193607, -0.66088375],\n",
      "        [-0.50149925, -0.32189098, -0.43584919, ..., -0.47175477,\n",
      "         -0.53156049, -0.80021735],\n",
      "        [-0.75911698, -0.64004558, -0.78821626, ..., -0.7657261 ,\n",
      "         -0.80471977, -0.94680321],\n",
      "        ...,\n",
      "        [ 0.50314031,  0.39092189,  0.38160487, ...,  0.22100298,\n",
      "          0.49684737,  0.42768809],\n",
      "        [ 0.55458576,  0.48248048,  0.46218063, ...,  0.40183864,\n",
      "          0.60585596,  0.53248389],\n",
      "        [ 1.        ,  1.        ,  1.        , ...,  0.91274277,\n",
      "          1.        ,  0.81221469]],\n",
      "\n",
      "       [[-0.7698598 , -0.36630824, -0.57768433, ..., -0.13172701,\n",
      "         -0.25183733, -0.21158548],\n",
      "        [-0.65505008, -0.18189465, -0.35393941, ..., -0.04047103,\n",
      "         -0.24194411, -0.20391181],\n",
      "        [-0.48262244,  0.0334212 , -0.06990568, ...,  0.13870596,\n",
      "         -0.14305117, -0.12496311],\n",
      "        ...,\n",
      "        [ 0.07201655, -0.50569296,  0.37765208, ...,  0.18141753,\n",
      "          0.00847773,  0.24919971],\n",
      "        [-0.04462381, -0.62791463,  0.28174628, ...,  0.21998494,\n",
      "          0.05152084,  0.24500233],\n",
      "        [-0.35708268, -1.        , -0.14317121, ...,  0.04774102,\n",
      "         -0.16930559,  0.11383293]]])>, 'Marker_6': <tf.Tensor: shape=(62, 385, 16), dtype=float64, numpy=\n",
      "array([[[-8.14874922e-01, -7.75809086e-01,  1.62122893e-01, ...,\n",
      "         -7.95488297e-01, -1.24234931e-01, -4.11295572e-01],\n",
      "        [-9.31006522e-01, -9.48600448e-01, -2.70629368e-01, ...,\n",
      "         -8.97840969e-01, -2.97685014e-01, -5.34920181e-01],\n",
      "        [-9.08212664e-01, -9.49497679e-01, -7.71538068e-01, ...,\n",
      "         -8.90117232e-01, -2.29349396e-01, -5.26331080e-01],\n",
      "        ...,\n",
      "        [-8.44788689e-02,  5.38787791e-01, -1.77728611e-01, ...,\n",
      "          3.12233040e-01,  3.59141616e-01,  5.98426956e-01],\n",
      "        [ 4.81461385e-04,  6.59470072e-01, -6.31170043e-02, ...,\n",
      "          3.94825781e-01,  3.68823680e-01,  6.04589503e-01],\n",
      "        [ 5.82617171e-02,  7.52189014e-01,  7.20232929e-01, ...,\n",
      "          5.36061547e-01,  2.80034646e-01,  6.52578353e-01]],\n",
      "\n",
      "       [[-5.83779032e-01, -8.66377916e-01, -7.26100481e-01, ...,\n",
      "         -1.13378050e-01,  2.03924178e-03, -5.18520548e-01],\n",
      "        [-3.45091889e-01, -6.22417043e-01, -6.70067494e-01, ...,\n",
      "          3.65941900e-02,  2.05232892e-01, -2.83090608e-01],\n",
      "        [-1.33257441e-01, -3.71539011e-01, -5.69377396e-02, ...,\n",
      "          1.92205921e-01,  3.21681235e-01, -1.73487351e-01],\n",
      "        ...,\n",
      "        [ 2.01007664e-02,  4.64595744e-01,  6.25913051e-01, ...,\n",
      "          1.67811162e-01,  2.05873484e-01,  3.56244135e-01],\n",
      "        [ 2.29271989e-02,  4.65846807e-01,  9.55598789e-01, ...,\n",
      "          3.22798654e-01,  3.57119003e-01,  4.09132914e-01],\n",
      "        [-2.19980615e-01,  1.65026236e-01,  4.22411900e-01, ...,\n",
      "          2.71350125e-01,  4.76021078e-01,  2.27937542e-01]],\n",
      "\n",
      "       [[-5.02306511e-01, -9.32800817e-01, -6.85953557e-01, ...,\n",
      "         -5.41540980e-01,  2.92943062e-02, -6.34828931e-01],\n",
      "        [-3.72147375e-01, -8.59021741e-01, -3.73120671e-01, ...,\n",
      "         -4.45469919e-01,  1.06193982e-01, -5.97376167e-01],\n",
      "        [-3.14550672e-01, -8.38830959e-01, -2.45109637e-01, ...,\n",
      "         -2.56167445e-01,  2.30140576e-01, -4.61802811e-01],\n",
      "        ...,\n",
      "        [-2.75929334e-01,  1.96190916e-01, -2.41662666e-01, ...,\n",
      "         -2.47726402e-01, -1.53733643e-01, -7.31952849e-01],\n",
      "        [-3.50133232e-01,  9.49369938e-02, -4.39933094e-01, ...,\n",
      "         -3.82524994e-01, -1.99714405e-02, -8.34388759e-01],\n",
      "        [-3.50427356e-01,  3.47674641e-02, -6.61570366e-01, ...,\n",
      "         -4.97665650e-01, -8.90806708e-02, -8.76405637e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-3.31099169e-01, -1.26074573e-01,  5.27989986e-02, ...,\n",
      "          1.38788506e-01, -1.42284549e-02, -4.08064107e-01],\n",
      "        [-3.55688694e-01, -1.76514387e-01, -3.59129553e-02, ...,\n",
      "          7.30707844e-02, -2.34515447e-02, -4.39878422e-01],\n",
      "        [-5.33926747e-01, -3.84854771e-01, -4.34057726e-01, ...,\n",
      "         -1.37653831e-01, -1.51053208e-01, -5.53286579e-01],\n",
      "        ...,\n",
      "        [-3.08422373e-01, -4.18141900e-01, -1.09961380e-01, ...,\n",
      "          3.99234380e-01, -2.13538355e-01,  7.40530609e-01],\n",
      "        [-3.91796593e-01, -4.73806995e-01, -1.80287911e-01, ...,\n",
      "          3.67125362e-01, -3.33354184e-01,  7.23914674e-01],\n",
      "        [-1.63505809e-01, -1.27007529e-01,  4.33249428e-01, ...,\n",
      "          5.37400509e-01, -3.22629734e-01,  7.58792204e-01]],\n",
      "\n",
      "       [[-2.32318839e-01,  6.46304224e-02, -6.00735789e-02, ...,\n",
      "         -1.00661029e-01, -8.88532378e-02,  1.95047453e-01],\n",
      "        [-3.61093911e-01, -1.48817420e-01, -3.03429711e-01, ...,\n",
      "         -3.15124611e-01, -2.56077333e-01, -1.35923559e-01],\n",
      "        [-4.82461864e-01, -3.22509437e-01, -5.14852963e-01, ...,\n",
      "         -4.99687399e-01, -4.18705350e-01, -3.76085702e-01],\n",
      "        ...,\n",
      "        [-4.06201607e-01, -5.45763138e-01,  7.74127010e-02, ...,\n",
      "         -4.76014266e-01, -4.62778033e-01, -5.07191345e-01],\n",
      "        [-3.48355887e-01, -4.48963240e-01,  1.76801904e-01, ...,\n",
      "         -4.71010304e-01, -4.53794649e-01, -5.24477775e-01],\n",
      "        [-1.66711557e-01, -2.05226022e-01,  4.61501096e-01, ...,\n",
      "         -3.08046180e-01, -3.21201135e-01, -4.10667139e-01]],\n",
      "\n",
      "       [[-3.78092008e-01, -3.34574304e-01, -4.20141770e-01, ...,\n",
      "          3.27693922e-01,  1.13755936e-01,  6.28672541e-01],\n",
      "        [-4.40156691e-01, -3.54483869e-01, -5.09716354e-01, ...,\n",
      "          3.10837845e-01,  1.05304477e-01,  6.42500731e-01],\n",
      "        [-3.62704344e-01, -2.42523769e-01, -3.63191205e-01, ...,\n",
      "          3.72244793e-01,  2.01260290e-01,  7.10734935e-01],\n",
      "        ...,\n",
      "        [-6.63276912e-01, -5.65430422e-01, -4.73076260e-01, ...,\n",
      "         -6.24149612e-01, -6.19293149e-01, -6.85923148e-01],\n",
      "        [-6.15109026e-01, -5.30440869e-01, -3.97949376e-01, ...,\n",
      "         -6.42923837e-01, -6.40304078e-01, -6.83343647e-01],\n",
      "        [-7.38139228e-01, -7.10113329e-01, -6.61346905e-01, ...,\n",
      "         -7.77039371e-01, -7.69592632e-01, -7.63132774e-01]]])>}\n",
      "{'Marker_1': 63, 'Marker_2': 80, 'Marker_3': 83, 'Marker_4': 75, 'Marker_5': 78, 'Marker_6': 62}\n"
     ]
    }
   ],
   "source": [
    "def agrupar_datos(suj):\n",
    "    m=get_event_sujxrun(ruta, f\"{suj}\") \n",
    "    markers = {\"Marker_1\": [], \"Marker_2\": [], \"Marker_3\": [], \"Marker_4\": [], \"Marker_5\": [], \"Marker_6\": []}\n",
    "    length_datos = {mark: 0 for mark in m}\n",
    "\n",
    "    for mark, value in m.items():\n",
    "        if mark in markers:\n",
    "            markers[mark].extend(value)  \n",
    "            length_datos[mark] += len(value)\n",
    "\n",
    "    tensorxsuj = {}\n",
    "\n",
    "    for key, value in markers.items():\n",
    "        tensorxsuj[key] = tf.reshape(tf.convert_to_tensor(value), (length_datos[key], 385, 16))\n",
    "    \n",
    "    return tensorxsuj, length_datos\n",
    "\n",
    "tensorxsuj, length_datos = agrupar_datos(1)\n",
    "\n",
    "print(tensorxsuj)\n",
    "print(length_datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "suj = {\"Suj_1\": [], \"Suj_2\": [], \"Suj_3\": [], \"Suj_4\": [], \"Suj_5\": [], \"Suj_6\": []}\n",
    "markers = {\"Marker_1\": [], \"Marker_2\": [], \"Marker_3\": [], \"Marker_4\": [], \"Marker_5\": [], \"Marker_6\": []}\n",
    "for n in range(1, 7):\n",
    "    tensorxsuj, length_datos = agrupar_datos(n)\n",
    "    suj[f\"Suj_{n}\"] = tensorxsuj\n",
    "    \n",
    "# Diccionario para almacenar los datos agrupados por marcador\n",
    "datos_por_mark = {\"Marker_1\": [], \"Marker_2\": [], \"Marker_3\": [], \"Marker_4\": [], \"Marker_5\": [], \"Marker_6\": []}\n",
    "\n",
    "for sujeto, datos in suj.items():\n",
    "    for marker, tensor in datos.items():\n",
    "        if marker in datos_por_mark:\n",
    "            datos_por_mark[marker].append(tensor)\n",
    "\n",
    "for marker, tensores in datos_por_mark.items():\n",
    "    datos_por_mark[marker] = tf.concat(tensores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 385, 16)\n"
     ]
    }
   ],
   "source": [
    "print(datos_por_mark[\"Marker_1\"].shape)\n",
    "#print(datos_por_mark[\"Marker_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datos_por_mark[\"Marker_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(length_datos, marker):\n",
    "    # Valores por clase\n",
    "    valores = {\"Marker_1\": 0, \"Marker_2\": 1, \"Marker_3\": 2, \"Marker_4\": 3, \"Marker_5\": 4, \"Marker_6\": 5}\n",
    "    \n",
    "    # Obtener el valor correspondiente al marcador\n",
    "    n = valores[f\"Marker_{marker}\"]\n",
    "    \n",
    "    tensor = tf.fill((length_datos, 16), n)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos =datos_por_mark\n",
    "length_datos = d.shape[0]\n",
    "labels = get_labels(length_datos, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_datos = d.shape[0]\n",
    "labels = get_labels(length_datos, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(331, 16), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos =datos_por_mark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 <class 'torch.utils.data.dataset.Subset'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "#datos= datos[\"Marker_1\"]\n",
    "batch_size = 32\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(datos, [0.8, 0.2])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "# Checking lengths of train_loader and val_loader, and type of train_set\n",
    "print(len(train_loader), len(val_loader), type(train_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader por que se escargar los datos en lotes(batches), procesa multiples muestras a la vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datos[\"Marker_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(331, 385, 16), dtype=float64, numpy=\n",
       "array([[[-0.7265575 , -0.65101729, -1.        , ..., -0.50346511,\n",
       "         -0.32013615, -0.59905516],\n",
       "        [-0.67816966, -0.5985542 , -0.56414983, ..., -0.28778956,\n",
       "         -0.09780727, -0.67023779],\n",
       "        [-0.64119087, -0.58064911, -0.16354134, ...,  0.06860901,\n",
       "          0.20599897, -0.55113152],\n",
       "        ...,\n",
       "        [-0.14065726,  0.2359265 ,  0.81640086, ...,  0.27196593,\n",
       "          0.39501937,  0.85777496],\n",
       "        [-0.1461181 ,  0.22426275,  0.60313194, ...,  0.45532535,\n",
       "          0.5060532 ,  0.9429678 ],\n",
       "        [-0.32565557,  0.05800861, -0.18401914, ...,  0.34971831,\n",
       "          0.15307825,  0.95560016]],\n",
       "\n",
       "       [[ 0.52829984, -0.75924963, -0.12009981, ...,  0.13848112,\n",
       "         -0.95876275, -0.23228808],\n",
       "        [ 0.58500486, -0.65135342, -0.58990202, ...,  0.25117881,\n",
       "         -0.61907484,  0.09356379],\n",
       "        [ 0.64733311, -0.52450758, -0.32888821, ...,  0.40487155,\n",
       "         -0.25194263,  0.41252575],\n",
       "        ...,\n",
       "        [-0.62898839,  0.1398107 ,  0.34746827, ..., -0.89976146,\n",
       "         -0.26786495, -0.71149954],\n",
       "        [-0.693175  ,  0.12708773,  0.6826344 , ..., -0.8600638 ,\n",
       "         -0.2594464 , -0.65002733],\n",
       "        [-1.        , -0.09184797,  0.26584414, ..., -0.8970551 ,\n",
       "         -0.40183441, -0.67116057]],\n",
       "\n",
       "       [[-0.45585639,  0.00199508, -1.        , ..., -0.65417538,\n",
       "         -0.56656892, -0.17880674],\n",
       "        [-0.45649706,  0.05906948, -0.07339887, ..., -0.48006568,\n",
       "         -0.22081532, -0.43847434],\n",
       "        [-0.41225228,  0.1413835 , -0.10132114, ..., -0.31713824,\n",
       "          0.03898659, -0.37736832],\n",
       "        ...,\n",
       "        [-0.80171564, -0.74387034,  0.12817464, ...,  0.47087216,\n",
       "          0.45513221,  0.23370951],\n",
       "        [-0.81361944, -0.76423274, -0.31703053, ...,  0.20570523,\n",
       "          0.4188673 ,  0.08637545],\n",
       "        [-0.74924188, -0.69219813,  0.08047193, ..., -0.00630357,\n",
       "          0.35686706, -0.06883427]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.78587616, -0.79198895, -0.71543508, ..., -0.8043447 ,\n",
       "         -1.        , -0.79454035],\n",
       "        [-0.63196263, -0.59122726, -0.39906466, ..., -0.51346857,\n",
       "         -0.35837898, -0.52219327],\n",
       "        [-0.54245019, -0.47621229, -0.24581618, ..., -0.26096957,\n",
       "         -0.05623346, -0.2456618 ],\n",
       "        ...,\n",
       "        [ 0.49693596,  0.46995602,  0.35660411, ...,  0.57789307,\n",
       "          0.47974175,  0.39805962],\n",
       "        [ 0.46782225,  0.48490896,  0.4089197 , ...,  0.73653627,\n",
       "          0.24024848,  0.50652654],\n",
       "        [ 0.37525288,  0.45431662,  0.40492748, ...,  0.83806411,\n",
       "         -0.65250766,  0.40147724]],\n",
       "\n",
       "       [[-0.98536855, -0.16017258, -0.57808708, ..., -0.60756927,\n",
       "         -0.37549826, -0.3200075 ],\n",
       "        [-0.74786865,  0.01372668, -0.50602865, ..., -0.32439608,\n",
       "         -0.20729473,  0.00473331],\n",
       "        [-0.74726473, -0.02827121, -0.61669037, ..., -0.4707943 ,\n",
       "         -0.33823536, -0.15225999],\n",
       "        ...,\n",
       "        [-0.55475637, -0.73719545, -0.48358993, ..., -0.25681065,\n",
       "         -0.40893744, -0.20036121],\n",
       "        [-0.63974583, -0.84583337, -0.60711407, ..., -0.52720378,\n",
       "         -0.1466917 , -0.40000228],\n",
       "        [-0.44918442, -0.73992451, -0.53972313, ..., -0.71800381,\n",
       "          1.        , -0.72360805]],\n",
       "\n",
       "       [[-0.60977329, -0.42380914, -0.62349966, ..., -1.        ,\n",
       "          1.        , -1.        ],\n",
       "        [-0.77395661, -0.61251092, -0.73279235, ..., -0.9495069 ,\n",
       "          0.14369032, -0.86610404],\n",
       "        [-0.51103439, -0.37396069, -0.44899998, ..., -0.41662797,\n",
       "         -0.0764972 , -0.3349792 ],\n",
       "        ...,\n",
       "        [-0.38508295, -0.25662602,  0.05921069, ...,  0.2734257 ,\n",
       "         -0.24136805, -0.03421113],\n",
       "        [ 0.01196499,  0.15851654,  0.53550253, ...,  0.73238182,\n",
       "         -0.01381172,  0.4478948 ],\n",
       "        [ 0.14415111,  0.32028322,  0.78742614, ...,  0.87678626,\n",
       "         -0.23507344,  0.53538407]]])>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(331, 16), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MioDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, inputs, labels, batch_size):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return tf.data.experimental.cardinality(self.inputs).numpy()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_inputs = self.inputs[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        return batch_inputs, batch_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y validación\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = len(data) - train_size\n",
    "\n",
    "train_inputs, val_inputs = data[:train_size], data[train_size:]\n",
    "train_labels, val_labels = labels[:train_size], labels[train_size:]\n",
    "\n",
    "# Crear instancias de la clase MioDataset para entrenamiento y validación\n",
    "batch_size = 32\n",
    "train_dataset = MioDataset(train_inputs, train_labels, batch_size)\n",
    "val_dataset = MioDataset(val_inputs, val_labels, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos2 =datos_por_mark[\"Marker_2\"]\n",
    "length_datos2 = datos2.shape[0]\n",
    "labels2 = get_labels(length_datos2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos2 =datos_por_mark[\"Marker_2\"]\n",
    "length_datos2 = datos2.shape[0]\n",
    "labels2 = get_labels(length_datos2, 2)\n",
    "# Dividir el conjunto de datos en entrenamiento y validación\n",
    "train_size = int(0.8 * len(datos2))\n",
    "val_size = len(datos2) - train_size\n",
    "\n",
    "train_inputs2, val_inputs2 = datos2[:train_size], datos2[train_size:]\n",
    "train_labels2, val_labels2 = labels2[:train_size], labels2[train_size:]\n",
    "\n",
    "# Crear instancias de la clase MioDataset para entrenamiento y validación\n",
    "batch_size = 32\n",
    "train_dataset2 = MioDataset(train_inputs2, train_labels2, batch_size)\n",
    "val_dataset2 = MioDataset(val_inputs2, val_labels2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv1D(64, 3, activation='relu', input_shape=input_shape), #capa de entrada, en esta capa se establece formato de entrada\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(32, 3, activation='relu'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(16, activation='softmax') # Capa de salida con una neurona para clasificación binaria\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', # Usar categorical_crossentropy para clasificación multiclase\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= conv1d_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">383</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3008</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">192,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m383\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m3,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m189\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_15 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3008\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m192,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,928</span> (792.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,928\u001b[0m (792.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,928</span> (792.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,928\u001b[0m (792.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1377 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0649 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0743 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0544 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0578 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0576 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0500 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0643 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0750 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0776 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0729 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0624 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0456 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0666 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0518 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0649 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0623 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0788 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0637 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0543 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0707 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0486 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0673 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0566 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0580 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0734 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0646 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0601 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0531 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0804 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0522 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0540 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0682 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0539 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0711 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0735 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0599 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0566 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0639 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0608 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0591 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0560 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0595 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0605 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0508 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0611 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0603 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0586 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0597 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0522 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0644 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0795 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0590 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0372 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0738 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0572 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0791 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0643 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0528 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0657 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0488 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0705 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0631 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0599 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0541 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0754 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0721 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0528 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0593 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0437 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0638 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0579 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0675 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0686 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0700 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0637 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0685 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0600 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0665 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0481 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0600 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0701 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0583 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0601 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0654 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0603 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0660 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0648 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0555 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0578 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0689 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0849 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0609 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0536 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0629 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0571 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0578 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0659 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0596 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0505 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_inputs, train_labels, epochs=100, batch_size=1, validation_data=(val_inputs, val_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
